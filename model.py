import torch
import segmentation_models_pytorch as smp
import cv2
import numpy as np
import os
from background_editor import BackgroundEditor

class HumanSegmentator:
    def __init__(self, model_path=None):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ç–æ—Ä–∞ –Ω–∞ {self.device}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        if model_path and os.path.exists(model_path):
            self.model = self.load_improved_model(model_path)
            self.image_size = (512, 512)
        else:
            self.model = self.load_basic_model() 
            self.image_size = (256, 256)
            
        self.model.to(self.device)
        self.model.eval()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ —Ñ–æ–Ω–æ–≤
        self.background_editor = BackgroundEditor()
    
    def load_basic_model(self):
        print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
        model = smp.Unet(
            encoder_name="resnet18",
            encoder_weights="imagenet", 
            classes=1,
            activation="sigmoid"
        )
        return model
    
    def load_improved_model(self, model_path):
        print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
        model = smp.Unet(
            encoder_name="resnet34", 
            encoder_weights=None,
            classes=1,
            activation="sigmoid"
        )
        model.load_state_dict(torch.load(model_path, map_location=self.device))
        return model
    
    def process_image(self, image_path_or_array, background_type="blue", custom_background=None, effects=None):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —ç—Ñ—Ñ–µ–∫—Ç–æ–≤"""
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if isinstance(image_path_or_array, str):
            image = cv2.imread(image_path_or_array)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            image = image_path_or_array
        
        original_size = image.shape[:2]
        
        # –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        processed = self.preprocess_image(image)
        mask = self.predict_mask(processed)
        final_mask = self.postprocess_mask(mask, original_size)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ–Ω–∞ —Å —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏
        result = self.apply_background_with_effects(image, final_mask, background_type, custom_background, effects)
        
        return final_mask, result
    
    def preprocess_image(self, image):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        image_resized = cv2.resize(image, self.image_size)
        image_tensor = torch.from_numpy(image_resized).permute(2, 0, 1).unsqueeze(0)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)
        std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)
        image_tensor = (image_tensor.float() / 255.0 - mean) / std
        
        return image_tensor.to(self.device)
    
    def predict_mask(self, image_tensor):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–∞—Å–∫–∏"""
        with torch.no_grad():
            output = self.model(image_tensor)
            mask = torch.sigmoid(output).squeeze().cpu().numpy()
        return mask
    
    def postprocess_mask(self, mask, original_size):
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å–∫–∏"""
        mask_resized = cv2.resize(mask, (original_size[1], original_size[0]))
        binary_mask = (mask_resized > 0.5).astype(np.uint8) * 255
        
        # –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—Å–∫–∏
        kernel = np.ones((5,5), np.uint8)
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)
        binary_mask = cv2.GaussianBlur(binary_mask, (5,5), 0)
        
        return (binary_mask > 128).astype(np.uint8) * 255
    
    def apply_background_with_effects(self, image, mask, background_type, custom_background, effects):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ–Ω–∞ —Å —ç—Ñ—Ñ–µ–∫—Ç–∞–º–∏"""
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–æ–Ω
        if custom_background is not None:
            if isinstance(custom_background, str):
                background = cv2.imread(custom_background)
                background = cv2.cvtColor(background, cv2.COLOR_BGR2RGB)
            else:
                background = custom_background
            
            if background.shape[:2] != image.shape[:2]:
                background = cv2.resize(background, (image.shape[1], image.shape[0]))
        else:
            background = self.generate_background(image.shape, background_type)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —ç—Ñ—Ñ–µ–∫—Ç—ã –∫ —Ñ–æ–Ω—É
        if effects:
            background = self.background_editor.apply_effects(background, effects)
        
        # –ü–ª–∞–≤–Ω–æ–µ —Å–º–µ—à–∏–≤–∞–Ω–∏–µ
        smooth_mask = mask.astype(np.float32) / 255.0
        smooth_mask = cv2.GaussianBlur(smooth_mask, (7,7), 0)
        smooth_mask = np.stack([smooth_mask]*3, axis=2)
        
        result = image * smooth_mask + background * (1 - smooth_mask)
        return result.astype(np.uint8)
    
    def generate_background(self, image_shape, background_type):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ —Ñ–æ–Ω–∞"""
        h, w = image_shape[:2]
        
        if background_type == "blue":
            return np.full((h,w,3), [255,0,0], dtype=np.uint8)
        elif background_type == "green":
            return np.full((h,w,3), [0,255,0], dtype=np.uint8)
        elif background_type == "black":
            return np.zeros((h,w,3), dtype=np.uint8)
        elif background_type == "blur":
            return cv2.GaussianBlur(np.zeros((h,w,3)), (51,51), 0)
        elif background_type == "gradient":
            background = np.zeros((h,w,3), dtype=np.uint8)
            for i in range(h):
                progress = i / h
                blue = int(255 * (1-progress))
                red = int(255 * progress)
                background[i,:] = [blue, 128, red]
            return background
        else:
            return np.full((h,w,3), [255,0,0], dtype=np.uint8)  # –°–∏–Ω–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é